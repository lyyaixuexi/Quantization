# ------------- general options ----------------------------------------
save_path = "/mnt/cephfs/home/lyy/NFS/mixed_quantization/auto_compress_ft/binary_gate/resnet/" # log path
data_path = "/mnt/ssd/datasets/" # path for dataset folder, containing cifar10 and imagenet
#data_path = "/home/dataset/"
#data_path = "/mnt/cephfs/dataset"
dataset = "imagenet"  # options: imagenet | cifar10
seed = 1  # manually set RNG seed
gpu = "5,6,7"  # GPU id to use, e.g. "0,1,2,3"
print_frequency = 10

# ------------- data options -------------------------------------------
n_threads = 4  # number of threads used for data loading
n_classes = 1000  # number of classes in the dataset

# ------------- common optimization options ---------------------------
batch_size = 64  # mini-batch size
momentum = 0.9  # momentum
weight_decay = 1e-4  # weight decay
lr = 0.01  # initial learning rate
n_epochs = 15  # number of total epochs
step = [25, 30]  # multi-step for linear learning rate
lr_scheduler_type = 'cosine'
opt_type = 'SGD'
warmup_lr = 0.001
warmup_n_iters = 0

# ------------- model options ------------------------------------------
net_type = "qresnet"  # options: resnet | preresnet
experiment_id = "sgdmn_supernet_compress_gate_max_0.035_cp004_34027_cosine_get_bits_20230405"  # experiment identifier
depth = 18  # resnet depth: (n-2)%6==0
loss_lambda = 0.035
quantize_first_last = True
num_choices = 16
group_size = 16
max_pruning_ratio = 0.2

# ------------- quantization options -----------------------------------
qw = 2
qa = 2
bits_weights_list = [2,4,8]
bits_activations_list = [2,4,8]

# ------------- resume or retrain options ------------------------------
pretrained = "/mnt/cephfs/home/lyy/NFS/mixed_quantization/auto_compress/binary_gate/resnet/log_super_compress_gate_resnet_imagenet_w2a2_bs64_e10_lr0.01000_step[25, 30]_lambda0.05_gp16_maxp0.2_sgdmn_supernet_compress_gate_indicator_pytorch_init_2021040301/check_point/best_model.pth"  # path of the pre-trained model
mixed_precision_pretrained = ""
resume = "" # resume checkpoint